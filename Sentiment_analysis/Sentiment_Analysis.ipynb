{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código se enfoca en evaluar el sentimiento de cada revisión en base a si se recomienda o no, asignándole una puntuación de análisis de sentimientos. Antes de realizar este análisis, se aplica un proceso de stemming utilizando PorterStemmer, mediante la función apply_stemming, que actúa sobre la columna 'review' del DataFrame. Esto implica reducir las palabras a su forma base para capturar de manera más efectiva el significado general y disminuir la complejidad del texto. Se optó por el stemming debido a su rapidez, aunque es importante tener en cuenta que es un proceso más agresivo que la lematización. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Importamos las librerías necesarias para realizar el análisis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer  # Importar el stemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer  # Importar el lematizador\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')  # Descargar el modelo vader_lexicon de NLTK\n",
    "nltk.download('punkt')  # Descargar el tokenizer de NLTK\n",
    "nltk.download('wordnet')  # Descargar WordNet para lematización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el dataset:\\\n",
    "*Cargamos el dataset en un DataFrame de pandas para poder manipularlo y realizar el análisis de sentimiento.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'C:\\Users\\Usuario\\Desktop\\proyecto steam\\Data Exportada\\user_reviews_clean.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hacemos una copia para realizar las operaciones, mientras resguardamos los datos en el archivo original.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>posted</th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>Posted November 5, 2011.</td>\n",
       "      <td>1250</td>\n",
       "      <td>True</td>\n",
       "      <td>Simple yet with great replayability. In my opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>Posted July 15, 2011.</td>\n",
       "      <td>22200</td>\n",
       "      <td>True</td>\n",
       "      <td>It's unique and worth a playthrough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>Posted April 21, 2011.</td>\n",
       "      <td>43110</td>\n",
       "      <td>True</td>\n",
       "      <td>Great atmosphere. The gunplay can be a bit chu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>js41637</td>\n",
       "      <td>Posted June 24, 2014.</td>\n",
       "      <td>251610</td>\n",
       "      <td>True</td>\n",
       "      <td>I know what you think when you see this title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>js41637</td>\n",
       "      <td>Posted September 8, 2013.</td>\n",
       "      <td>227300</td>\n",
       "      <td>True</td>\n",
       "      <td>For a simple (it's actually not all that simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59328</th>\n",
       "      <td>76561198312638244</td>\n",
       "      <td>Posted July 10.</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>a must have classic from steam definitely wort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59329</th>\n",
       "      <td>76561198312638244</td>\n",
       "      <td>Posted July 8.</td>\n",
       "      <td>362890</td>\n",
       "      <td>True</td>\n",
       "      <td>this game is a perfect remake of the original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59330</th>\n",
       "      <td>LydiaMorley</td>\n",
       "      <td>Posted July 3.</td>\n",
       "      <td>273110</td>\n",
       "      <td>True</td>\n",
       "      <td>had so much fun plaing this and collecting res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59331</th>\n",
       "      <td>LydiaMorley</td>\n",
       "      <td>Posted July 20.</td>\n",
       "      <td>730</td>\n",
       "      <td>True</td>\n",
       "      <td>:D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59332</th>\n",
       "      <td>LydiaMorley</td>\n",
       "      <td>Posted July 2.</td>\n",
       "      <td>440</td>\n",
       "      <td>True</td>\n",
       "      <td>so much fun :D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59333 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id                     posted item_id recommend  \\\n",
       "0      76561197970982479   Posted November 5, 2011.    1250      True   \n",
       "1      76561197970982479      Posted July 15, 2011.   22200      True   \n",
       "2      76561197970982479     Posted April 21, 2011.   43110      True   \n",
       "3                js41637      Posted June 24, 2014.  251610      True   \n",
       "4                js41637  Posted September 8, 2013.  227300      True   \n",
       "...                  ...                        ...     ...       ...   \n",
       "59328  76561198312638244            Posted July 10.      70      True   \n",
       "59329  76561198312638244             Posted July 8.  362890      True   \n",
       "59330        LydiaMorley             Posted July 3.  273110      True   \n",
       "59331        LydiaMorley            Posted July 20.     730      True   \n",
       "59332        LydiaMorley             Posted July 2.     440      True   \n",
       "\n",
       "                                                  review  \n",
       "0      Simple yet with great replayability. In my opi...  \n",
       "1                   It's unique and worth a playthrough.  \n",
       "2      Great atmosphere. The gunplay can be a bit chu...  \n",
       "3      I know what you think when you see this title ...  \n",
       "4      For a simple (it's actually not all that simpl...  \n",
       "...                                                  ...  \n",
       "59328  a must have classic from steam definitely wort...  \n",
       "59329  this game is a perfect remake of the original ...  \n",
       "59330  had so much fun plaing this and collecting res...  \n",
       "59331                                                 :D  \n",
       "59332                                     so much fun :D  \n",
       "\n",
       "[59333 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos en la columna 'review'\n",
    "#df = df.dropna(subset=['review'])\n",
    "\n",
    "# Reemplazar expresiones\n",
    "df_copy['review'] = df_copy['review'].replace(['10/10', '100/100'], 'Excelent', regex=True)\n",
    "\n",
    "# Transformar todos los datos a tipo string\n",
    "df_copy['review'] = df_copy['review'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia para cada uno de los procesos donde: \n",
    "* Inicializamos el Analizador de Intensidad de Sentimiento (Sentiment Intensity Analyzer):\n",
    "* Inicializamos el stemmer\n",
    "* Inicializamos el lematizador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicación de Stemming a la Columna 'review' del DataFrame:\\\n",
    "*En este código, utilizamos el algoritmo de Stemming de NLTK para reducir las palabras a su forma base en la columna 'review' de nuestro DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la Función de Aplicación del Stemming\n",
    "def apply_stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Aplicar la función de stemming a la columna 'review' del DataFrame\n",
    "df_copy['review'] = df_copy['review'].apply(apply_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicación de Lematización a la Columna 'review' del DataFrame:\\\n",
    "En este código, utilizamos el algoritmo de Stemming de NLTK para reducir las palabras a su forma base en la columna 'review' de nuestro DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la Función de Aplicación de la Lematización\n",
    "def apply_lemmatization(text):\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Aplicar la función de lematización a la columna 'review' del DataFrame\n",
    "df_copy['review'] = df_copy['review'].apply(apply_lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicación del análisis de sentimiento:\\\n",
    "Creamos una función que tomará una reseña y aplicará el análisis de sentimiento, devolviendo el valor correspondiente según la escala especificada (malo='0', neutral='1' y positivo='2'). Si la reseña está ausente, la función devolverá '1'. Y luego la aplicamos al DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la Función de Análisis de Sentimiento\n",
    "def get_sentiment_score(text, recommend):\n",
    "    if pd.isnull(text):\n",
    "        return 1\n",
    "    sentiment_score = sid.polarity_scores(text)['compound']\n",
    "    if recommend:\n",
    "        sentiment_score += 0.5\n",
    "    else:\n",
    "        sentiment_score -= 0.5\n",
    "    if sentiment_score <= -0.05:\n",
    "        return 0\n",
    "    elif sentiment_score >= 0.05:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Aplicar la función get_sentiment_score a la columna de reseñas (review) para crear la nueva columna 'sentiment_analysis'.\n",
    "df_copy['sentiment_analysis'] = df_copy.apply(lambda row: get_sentiment_score(row['review'], row['recommend']), axis=1)\n",
    "df_copy.drop(columns=['review'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analizamos cómo se correlacionan los sentimientos expresados en las reseñas con las recomendaciones dadas por los usuarios.\n",
    "* Imprimimos en pantalla el conteo de las reseñas que muestran una inconsistencia entre el sentimiento expresado y la calificación dada por los usuarios, mostrando la cantidad de reseñas con sentimiento negativo y calificación positiva, así como la cantidad de reseñas con sentimiento positivo y calificación negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de reseñas con sentimiento negativo y recomendación positiva: 2904\n",
      "Conteo de reseñas con sentimiento positivo y recomendación negativa: 1323\n"
     ]
    }
   ],
   "source": [
    "# Reseñas con sentimiento positivo pero con una recomendación negativa.\n",
    "positive_negative = df_copy[(df_copy['sentiment_analysis'] == 2) & (df_copy['recommend'] == False)]\n",
    "\n",
    "# Reseñas con sentimiento negativo pero con una recomendación positiva.\n",
    "negative_positive = df_copy[(df_copy['sentiment_analysis'] == 0) & (df_copy['recommend'] == True)]\n",
    "\n",
    "# Conteo de reseñas con sentimiento negativo y recomendación positiva.\n",
    "count_negative_positive = len(negative_positive)\n",
    "\n",
    "# Conteo de reseñas con sentimiento positivo y recomendación negativa.\n",
    "count_positive_negative = len(positive_negative)\n",
    "\n",
    "print(\"Conteo de reseñas con sentimiento negativo y recomendación positiva:\", count_negative_positive)\n",
    "print(\"Conteo de reseñas con sentimiento positivo y recomendación negativa:\", count_positive_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el porcentaje de errores respecto de la cantidad total de registros para conocer el margen de error del análisis de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de errores: 7.124197326951275\n"
     ]
    }
   ],
   "source": [
    "total_mistakes = 2904 + 1323\n",
    "total_records = 59333\n",
    "percent_mistakes = (total_mistakes / total_records) * 100\n",
    "\n",
    "print(\"Porcentaje de errores:\", percent_mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Guardamos el DataFrame actualizado en un nuevo archivo .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_parquet(r'C:\\Users\\Usuario\\Desktop\\proyecto steam\\Sentiment_analysis\\Sentiment_Analysis_parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
